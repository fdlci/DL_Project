cuda:0
Paramaters to learn:
	 classifier.6.weight
	 classifier.6.bias
Epoch 0/49
----------
Using cache found in /gpfs/users/florezdi/.cache/torch/hub/pytorch_vision_v0.6.0
Training Tiny Loss: 1.9417 Acc: 0.3513
Val Tiny Loss: 1.3434 Acc: 0.5783
Epoch 1/49
----------
Training Tiny Loss: 1.0879 Acc: 0.6614
Val Tiny Loss: 1.2960 Acc: 0.6506
Epoch 2/49
----------
Training Tiny Loss: 1.0479 Acc: 0.6772
Val Tiny Loss: 0.9766 Acc: 0.7349
Epoch 3/49
----------
Training Tiny Loss: 0.9152 Acc: 0.7089
Val Tiny Loss: 0.9124 Acc: 0.7711
Epoch 4/49
----------
Training Tiny Loss: 0.8315 Acc: 0.7500
Val Tiny Loss: 0.9326 Acc: 0.7470
Epoch 5/49
----------
Training Tiny Loss: 0.7797 Acc: 0.7880
Val Tiny Loss: 1.1304 Acc: 0.7470
Epoch 6/49
----------
Training Tiny Loss: 0.7425 Acc: 0.7247
Val Tiny Loss: 0.9417 Acc: 0.6867
Epoch 7/49
----------
Training Tiny Loss: 0.6142 Acc: 0.8259
Val Tiny Loss: 0.8868 Acc: 0.7470
Epoch 8/49
----------
Training Tiny Loss: 0.5761 Acc: 0.8259
Val Tiny Loss: 0.8540 Acc: 0.7349
Epoch 9/49
----------
Training Tiny Loss: 0.5246 Acc: 0.8354
Val Tiny Loss: 0.8727 Acc: 0.7952
Epoch 10/49
----------
Training Tiny Loss: 0.5198 Acc: 0.8576
Val Tiny Loss: 0.8609 Acc: 0.7470
Epoch 11/49
----------
Training Tiny Loss: 0.5429 Acc: 0.8481
Val Tiny Loss: 0.8503 Acc: 0.7590
Epoch 12/49
----------
Training Tiny Loss: 0.5270 Acc: 0.8323
Val Tiny Loss: 0.8434 Acc: 0.7711
Epoch 13/49
----------
Training Tiny Loss: 0.5545 Acc: 0.8513
Val Tiny Loss: 0.8127 Acc: 0.7952
Epoch 14/49
----------
Training Tiny Loss: 0.6004 Acc: 0.8101
Val Tiny Loss: 0.8119 Acc: 0.7952
Epoch 15/49
----------
Training Tiny Loss: 0.5218 Acc: 0.8196
Val Tiny Loss: 0.8119 Acc: 0.7952
Epoch 16/49
----------
Training Tiny Loss: 0.4816 Acc: 0.8481
Val Tiny Loss: 0.8112 Acc: 0.7952
Epoch 17/49
----------
Training Tiny Loss: 0.5736 Acc: 0.8165
Val Tiny Loss: 0.8076 Acc: 0.7952
Epoch 18/49
----------
Training Tiny Loss: 0.5604 Acc: 0.8259
Val Tiny Loss: 0.8084 Acc: 0.7952
Epoch 19/49
----------
Training Tiny Loss: 0.5470 Acc: 0.8165
Val Tiny Loss: 0.8040 Acc: 0.7952
Epoch 20/49
----------
Training Tiny Loss: 0.5156 Acc: 0.8354
Val Tiny Loss: 0.8031 Acc: 0.7952
Epoch 21/49
----------
Training Tiny Loss: 0.4739 Acc: 0.8544
Val Tiny Loss: 0.8027 Acc: 0.7952
Epoch 22/49
----------
Training Tiny Loss: 0.5186 Acc: 0.8576
Val Tiny Loss: 0.8027 Acc: 0.7952
Epoch 23/49
----------
Training Tiny Loss: 0.5103 Acc: 0.8196
Val Tiny Loss: 0.8023 Acc: 0.7952
Epoch 24/49
----------
Training Tiny Loss: 0.4674 Acc: 0.8671
Val Tiny Loss: 0.8019 Acc: 0.7952
Epoch 25/49
----------
Training Tiny Loss: 0.4935 Acc: 0.8449
Val Tiny Loss: 0.8018 Acc: 0.7952
Epoch 26/49
----------
Training Tiny Loss: 0.6127 Acc: 0.8133
Val Tiny Loss: 0.8015 Acc: 0.7952
Epoch 27/49
----------
Training Tiny Loss: 0.5337 Acc: 0.8323
Val Tiny Loss: 0.8014 Acc: 0.7952
Epoch 28/49
----------
Training Tiny Loss: 0.4923 Acc: 0.8671
Val Tiny Loss: 0.8014 Acc: 0.7952
Epoch 29/49
----------
Training Tiny Loss: 0.5203 Acc: 0.8291
Val Tiny Loss: 0.8014 Acc: 0.7952
Epoch 30/49
----------
Training Tiny Loss: 0.5806 Acc: 0.8101
Val Tiny Loss: 0.8014 Acc: 0.7952
Epoch 31/49
----------
Training Tiny Loss: 0.5181 Acc: 0.8418
Val Tiny Loss: 0.8014 Acc: 0.7952
Epoch 32/49
----------
Training Tiny Loss: 0.4699 Acc: 0.8734
Val Tiny Loss: 0.8014 Acc: 0.7952
Epoch 33/49
----------
Training Tiny Loss: 0.4469 Acc: 0.8513
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 34/49
----------
Training Tiny Loss: 0.5053 Acc: 0.8481
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 35/49
----------
Training Tiny Loss: 0.5462 Acc: 0.8070
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 36/49
----------
Training Tiny Loss: 0.4668 Acc: 0.8386
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 37/49
----------
Training Tiny Loss: 0.6058 Acc: 0.8133
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 38/49
----------
Training Tiny Loss: 0.5352 Acc: 0.8291
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 39/49
----------
Training Tiny Loss: 0.4993 Acc: 0.8291
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 40/49
----------
Training Tiny Loss: 0.5708 Acc: 0.8228
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 41/49
----------
Training Tiny Loss: 0.5395 Acc: 0.8291
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 42/49
----------
Training Tiny Loss: 0.4477 Acc: 0.8544
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 43/49
----------
Training Tiny Loss: 0.4692 Acc: 0.8513
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 44/49
----------
Training Tiny Loss: 0.5777 Acc: 0.8323
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 45/49
----------
Training Tiny Loss: 0.4222 Acc: 0.8797
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 46/49
----------
Training Tiny Loss: 0.5166 Acc: 0.8259
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 47/49
----------
Training Tiny Loss: 0.4492 Acc: 0.8513
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 48/49
----------
Training Tiny Loss: 0.5757 Acc: 0.8070
Val Tiny Loss: 0.8013 Acc: 0.7952
Epoch 49/49
----------
Training Tiny Loss: 0.5373 Acc: 0.8323
Val Tiny Loss: 0.8013 Acc: 0.7952
validation loss: [1.3434460683759437, 1.296040879248316, 0.9765554732048368, 0.9123834779104555, 0.9326138665159065, 1.130403556198959, 0.9416684800512102, 0.8867525736610573, 0.8539986734289721, 0.8727020876235273, 0.8608571407665689, 0.8502951000918106, 0.8434346931795758, 0.8126891101878809, 0.8119043152420277, 0.8118958617728876, 0.811167233769434, 0.8075880775654531, 0.8083977922797203, 0.8039773236735758, 0.8031012232763222, 0.8027498043501323, 0.8026699613196304, 0.802295380328075, 0.801945409434567, 0.8018375685416073, 0.8015051834924842, 0.8013632499601647, 0.8013729802725544, 0.8013667023280658, 0.8013751327273357, 0.8013508785740439, 0.8013570527714419, 0.801333127274032, 0.8013242948127081, 0.8013224960360901, 0.8013211038995938, 0.8013197613363884, 0.8013188323701721, 0.8013205871614347, 0.801320194838995, 0.8013201773346189, 0.8013202015714473, 0.8013200105044497, 0.8013197989034725, 0.8013196102825992, 0.8013195426887777, 0.8013192821204304, 0.8013192991535347, 0.8013193031930061]
Training complete in 3m 12s
tensor([ True,  True,  True,  True, False, False,  True, False,  True,  True,
        False], device='cuda:0')
tensor([ True,  True,  True,  True, False,  True, False, False,  True,  True,
         True], device='cuda:0')
tensor([ True, False,  True,  True, False, False,  True,  True, False, False,
         True], device='cuda:0')

real	3m35.779s
user	10m40.104s
sys	1m4.353s
